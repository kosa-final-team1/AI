import streamlit as st
from langchain_core.messages.chat import ChatMessage
from langchain_openai import ChatOpenAI
from langchain_teddynote.models import MultiModal

from dotenv import load_dotenv
import os
#
#ìƒíƒœ ìš”ì•½: 
#
# API KEY ì •ë³´ë¡œë“œ
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    raise ValueError("[Error] OpenAI API Keyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤..")
        
# ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
if not os.path.exists(".cache"):
    os.mkdir(".cache")

# íŒŒì¼ ì—…ë¡œë“œ ì „ìš© í´ë”
if not os.path.exists(".cache/files"):
    os.mkdir(".cache/files")

if not os.path.exists(".cache/embeddings"):
    os.mkdir(".cache/embeddings")

st.set_page_config(page_title="AI Fashion Chatbot", page_icon="ðŸ‘š")
st.title(":gray[_AI FashionBot_]_Set the Looks ðŸ‘šðŸ”Ž")

# í˜„ìž¬ ì‹¤í–‰ ì¤‘ì¸ íŒŒì¼ëª…ì„ Streamlitì— í‘œì‹œ(ì–˜ ë„ˆë¬´ py ëŒì•„ê°€ë©´ì„œ ì‹¤í–‰í•´ì„œ í—·ê°ˆë ¤ì„œ ì¨ë†“ê¸°)
current_file_name = os.path.basename(__file__)
st.sidebar.write(f"py íŒŒì¼ëª…: `{current_file_name}`")

# ì²˜ìŒ 1ë²ˆë§Œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì½”ë“œ
if "messages" not in st.session_state:
    # ëŒ€í™”ê¸°ë¡ì„ ì €ìž¥í•˜ê¸° ìœ„í•œ ìš©ë„ë¡œ ìƒì„±í•œë‹¤.
    st.session_state["messages"] = []
    # st.session_state['messages'] = [{"role": "assistant", 
    #                                     "content": "ì•ˆë…•í•˜ì„¸ìš”! \b Set the Looks\b íŒ¨ì…˜ ê°€ì´ë“œ ì±—ë´‡ìž…ë‹ˆë‹¤.\b íŒ¨ì…˜ì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì´ ìžˆë‹¤ë©´ ì €ì—ê²Œ ìžìœ ë¡­ê²Œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”!"}]

# ì‚¬ì´ë“œë°” ìƒì„±
with st.sidebar:
    # ì´ˆê¸°í™” ë²„íŠ¼ ìƒì„±
    clear_btn = st.button("ëŒ€í™” ì´ˆê¸°í™”")

    # ì´ë¯¸ì§€ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader("ì´ë¯¸ì§€ ì—…ë¡œë“œ", type=["jpg", "jpeg", "png"], accept_multiple_files=True)
    
    # Process ë²„íŠ¼ ëˆŒë €ì„ ë•Œ ì´ë²¤íŠ¸ ì •ì˜
    #process = st.button("Process")
    
    system_prompt = st.text_area(
    "system", 
        """
        Your task is to classify the user's intent into one of the following categories: ["Fashion Recommendation", "Fashion Feedback", "General Conversation"].
        Based on the user's intent, generate a natural, friendly, and conversational response in Korean. Use emojis when appropriate, and do not show the classification process to the user. The user should only see the final response.

        - **Fashion Recommendation**: The user is asking for fashion advice, outfit suggestions, or styling recommendations. Examples include phrases like "ë¬´ìŠ¨ ì˜·ì„ ìž…ì–´ì•¼ í• ê¹Œìš”?", "ì´ ë“œë ˆìŠ¤ì— ë§žëŠ” ì‹ ë°œì„ ì¶”ì²œí•´ì¤˜.", "ìš”ì¦˜ ìœ í–‰ì´ ë­ëƒ", or "ì—¬ë¦„ì— ì–´ìš¸ë¦¬ëŠ” ìŠ¤íƒ€ì¼ì´ ë­ê°€ ìžˆì„ê¹Œ?".
        - **Fashion Feedback**: The user is providing feedback on a fashion item, discussing personal preferences, or commenting on a suggested style. Examples include phrases like "ì´ ì˜· ì–´ë•Œ", "ì¹œêµ¬ë“¤ì´ëž‘ ì—¬í–‰ê°€ëŠ”ë° ì´ëŸ° ë³µìž¥ ì–´ë–¨ê¹Œ", or "ìž¥ë¡€ì‹ì—ì„œ ìž…ì–´ë„ ë¼?".
        - **General Conversation**: The user is engaging in casual conversation unrelated to fashion advice or feedback. This could be small talk, general questions, or any other non-fashion related inquiry. Examples include phrases like "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë•Œìš”?", "ì–´ì œ ì˜í™” ë´¤ì–´?", "ì•„ ë°°ê³ í”„ë‹¤" or "ì§€ê¸ˆ ëª‡ ì‹œì˜ˆìš”?".

        Based on the classification, respond naturally without revealing the classification to the user.

        ====
        def classify(sentence: str) -> Literal["Fashion Recommendation", "Fashion Feedback", "General Conversation"]:
            Classify the user's sentence into one of the categories based on their intent.

            Args:
                sentence (str): The sentence that needs to be classified.

            Returns:
                Literal["Fashion Recommendation", "Fashion Feedback", "General Conversation"]: The classification of the sentence.
        ====
        # Generate a natural, friendly, conversational response in Korean based on the classification:
         if result == "Fashion Recommendation":
            return "ì´ ìŠ¤íƒ€ì¼ì€ ì •ë§ ì„¸ë ¨ë˜ë©´ì„œë„ ìœ ë‹ˆí¬í•œ ëŠë‚Œì„ ì¤„ ìˆ˜ ìžˆì–´ìš”! âœ¨ \n\n\
                    ì œê°€ ì¶”ì²œë“œë¦¬ëŠ” ìœ ì‚¬í•œ íŒ¨ì…˜ì€ ì´ ìŠ¤íƒ€ì¼ê³¼ ìž˜ ì–´ìš¸ë¦¬ëŠ” íŠ¸ë Œë””í•œ ì•„ì´í…œë“¤ìž…ë‹ˆë‹¤. ðŸ‘—ðŸ‘  \n\
                    íŠ¹ížˆ, ì´ ë“œë ˆìŠ¤ëŠ” ë‹¤ì–‘í•œ ì•¡ì„¸ì„œë¦¬ì™€ í•¨ê»˜ ë§¤ì¹˜í•˜ë©´ ë”ìš± ë‹ë³´ì¼ ê±°ì˜ˆìš”. ðŸ˜Š \n\n\
                    ì—¬ë¦„ì—ë„ ìž…ê¸° ì¢‹ì€ ì‹œì›í•œ ì†Œìž¬ë¡œ ì œìž‘ë˜ì—ˆê³ , ë°ì¼ë¦¬ ë£©ìœ¼ë¡œë„ ì™„ë²½í•˜ê²Œ ì–´ìš¸ë¦´ ê±°ì˜ˆìš”. \n\
                    ì´ ìŠ¤íƒ€ì¼ë¡œ ì‹œë„í•´ë³´ì‹œë©´ ë§Žì€ ì‚¬ëžŒë“¤ì´ ëˆˆì—¬ê²¨ë³´ê²Œ ë  ê±°ì˜ˆìš”! ðŸ‘"
        elif result == "Fashion Feedback":
            return "ì´ ì´ë¯¸ì§€ì— ìžˆëŠ” ì•„ì´í…œì€ ì •ë§ ë©‹ì§€ë„¤ìš”! ðŸŽ‰ \n\n\
                    ì´ ìŠ¤íƒ€ì¼ì€ ë‹¤ì–‘í•œ ì½”ë””ì— ìž˜ ì–´ìš¸ë¦´ ê²ƒ ê°™ì•„ìš”. ðŸ˜Š \n\
                    íŠ¹ížˆ ì´ ì•„ì´í…œì€ ì–´ë–¤ ë£©ì—ë„ í¬ì¸íŠ¸ë¥¼ ì¤„ ìˆ˜ ìžˆì–´ì„œ í™œìš©ë„ê°€ ë†’ì„ ê²ƒ ê°™ì•„ìš”!"
        elif result == "General Conversation":
            return "ê·¸ë ‡êµ°ìš”! ðŸ˜„ ì˜¤ëŠ˜ í•˜ë£¨ë„ ë©‹ì§„ í•˜ë£¨ ë³´ë‚´ì„¸ìš”! â˜€ï¸"
        
        Do not reveal the classification to the user. Only show the final response based on the classification.
        ("human", "{human}")
            """,
        height=100,
    )
    
    
# ì´ì „ ëŒ€í™”ë¥¼ ì¶œë ¥
def print_messages():
    for chat_message in st.session_state["messages"]:
        st.chat_message(chat_message.role).write(chat_message.content)


# ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì¶”ê°€
def add_message(role, message):
    st.session_state["messages"].append(ChatMessage(role=role, content=message))


# ì´ë¯¸ì§€ì„ ìºì‹œ ì €ìž¥(ì‹œê°„ì´ ì˜¤ëž˜ ê±¸ë¦¬ëŠ” ìž‘ì—…ì„ ì²˜ë¦¬í•  ì˜ˆì •)
@st.cache_resource(show_spinner="ðŸ‘— ì—…ë¡œë“œí•œ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬ ì¤‘ìž…ë‹ˆë‹¤...")
def process_imagefile(file):
    # ì—…ë¡œë“œí•œ íŒŒì¼ì„ ìºì‹œ ë””ë ‰í† ë¦¬ì— ì €ìž¥í•©ë‹ˆë‹¤.
    file_content = file.read()
    file_path = f"./.cache/files/{file.name}"

    with open(file_path, "wb") as f:
        f.write(file_content)

    return file_path


# í…ìŠ¤íŠ¸ ê¸°ë°˜ ë‹µë³€ ìƒì„±
def generate_text_answer(system_prompt, user_prompt, model_name):
    # ê°ì²´ ìƒì„±
    llm = ChatOpenAI(
        temperature=0,
        model_name=model_name,  # ëª¨ë¸ëª…
    )

    # GPT-4 ëª¨ë¸ì„ ì‚¬ìš©í•´ í…ìŠ¤íŠ¸ ê¸°ë°˜ì˜ ì‘ë‹µ ìƒì„±
    messages = [
        ChatMessage(role="system", content=system_prompt),
        ChatMessage(role="user", content=user_prompt)
    ]
    response = llm(messages)
    
    return response.content  # AIMessage ê°ì²´ì˜ content ì†ì„±ì„ ë°˜í™˜


# ì²´ì¸ ìƒì„± (ì´ë¯¸ì§€ ê¸°ë°˜ ë©€í‹°ëª¨ë‹¬ ì‘ë‹µ ìƒì„±)
def generate_multimodal_answer(image_filepath, system_prompt, user_prompt, model_name):
    # ê°ì²´ ìƒì„±
    llm = ChatOpenAI(
        temperature=0,
        model_name=model_name,  # ëª¨ë¸ëª…
    )

    # ë©€í‹°ëª¨ë‹¬ ê°ì²´ ìƒì„± (ì˜ˆì‹œë¡œ MultiModal ì‚¬ìš©)
    multimodal = MultiModal(llm, system_prompt=system_prompt, user_prompt=user_prompt)

    # ì´ë¯¸ì§€ íŒŒì¼ë¡œë¶€í„° ì§ˆì˜(ìŠ¤íŠ¸ë¦¼ ë°©ì‹)
    answer = multimodal.stream(image_filepath)
    return answer


# ì´ˆê¸°í™” ë²„íŠ¼ì´ ëˆŒë¦¬ë©´...
if clear_btn:
    st.session_state["messages"] = []

# ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
print_messages()

# ì‚¬ìš©ìžì˜ ìž…ë ¥
user_input = st.chat_input("íŒ¨ì…˜ì— ëŒ€í•´ ê¶ê¸ˆí•œ ê²ƒì´ ìžˆë‹¤ë©´ ì €ì—ê²Œ ìžìœ ë¡­ê²Œ ì§ˆë¬¸í•´ì£¼ì„¸ìš”!")

# ê²½ê³  ë©”ì‹œì§€ë¥¼ ë„ìš°ê¸° ìœ„í•œ ë¹ˆ ì˜ì—­
warning_msg = st.empty()

# ë§Œì•½ì— ì‚¬ìš©ìž ìž…ë ¥ì´ ë“¤ì–´ì˜¤ë©´...
if user_input:
    # ì‚¬ìš©ìžì˜ ìž…ë ¥ì„ ì¶”ê°€
    st.chat_message("user").write(user_input)

    if uploaded_file:
        # ë¦¬ìŠ¤íŠ¸ì˜ ë§ˆì§€ë§‰ ì´ë¯¸ì§€ë¡œ ê³„ì† ëŒ€í™”í•˜ê²Œ ì¶”ê°€
        new_uploaded_file = uploaded_file[-1]  
        # ì´ë¯¸ì§€ê°€ ìžˆìœ¼ë©´ ì´ë¯¸ì§€ì™€ í•¨ê»˜ ì²˜ë¦¬
        image_filepath = process_imagefile(new_uploaded_file)
        
        # ì´ë¯¸ì§€ ì‹œê°í™” ì¶”ê°€
        with st.chat_message("user"):
            #st.image(image_filepath, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€")
            st.image(image_filepath, caption=f"ì—…ë¡œë“œëœ ì´ë¯¸ì§€: {new_uploaded_file.name}")  # íŒŒì¼ëª… ì¶”ê°€

        response = generate_multimodal_answer(image_filepath, system_prompt, user_input, "gpt-4o")

        with st.chat_message("assistant"):
            # ë¹ˆ ê³µê°„(ì»¨í…Œì´ë„ˆ)ì„ ë§Œë“¤ì–´ì„œ, ì—¬ê¸°ì— í† í°ì„ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥í•œë‹¤.
            container = st.empty()

            ai_answer = ""
            for token in response:
                ai_answer += token.content
                container.markdown(ai_answer)

        # ëŒ€í™”ê¸°ë¡ì„ ì €ìž¥í•œë‹¤.
        add_message("user", user_input)
        add_message("assistant", ai_answer)

    else:
        # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬
        text_answer = generate_text_answer(system_prompt, user_input, "gpt-4")

        with st.chat_message("assistant"):
            st.write(text_answer)

        # ëŒ€í™”ê¸°ë¡ì„ ì €ìž¥í•œë‹¤.
        add_message("user", user_input)
        add_message("assistant", text_answer)
        

# ë§Œì•½ì— ì‚¬ìš©ìž ìž…ë ¥ì´ ë“¤ì–´ì˜¤ë©´...
if user_input:
    # ì‚¬ìš©ìžì˜ ìž…ë ¥ì„ ì¶”ê°€
    st.chat_message("user").write(user_input)

    if uploaded_file:
        new_uploaded_file = uploaded_file[-1]  
        # ì´ë¯¸ì§€ê°€ ìžˆìœ¼ë©´ ì´ë¯¸ì§€ì™€ í•¨ê»˜ ì²˜ë¦¬
        image_filepath = process_imagefile(new_uploaded_file)
        
        # ì´ë¯¸ì§€ ì‹œê°í™” ì¶”ê°€
        with st.chat_message("user"):
            st.image(image_filepath, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€")

        response = generate_multimodal_answer(image_filepath, system_prompt, user_input, 'gpt-4o')

        with st.chat_message("assistant"):
            # ë¹ˆ ê³µê°„(ì»¨í…Œì´ë„ˆ)ì„ ë§Œë“¤ì–´ì„œ, ì—¬ê¸°ì— í† í°ì„ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥í•œë‹¤.
            container = st.empty()

            ai_answer = ""
            for token in response:
                ai_answer += token.content
                container.markdown(ai_answer)

        # ëŒ€í™”ê¸°ë¡ì„ ì €ìž¥í•œë‹¤.
        add_message("user", user_input)
        add_message("assistant", ai_answer)

    else:
        # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬
        text_answer = generate_text_answer(system_prompt, user_input, 'gpt-4')

        with st.chat_message("assistant"):
            st.write(text_answer)

        # ëŒ€í™”ê¸°ë¡ì„ ì €ìž¥í•œë‹¤.
        add_message("user", user_input)
        add_message("assistant", text_answer)
        
import openai
import numpy as np

# ë²ˆì—­
def translate_text(text, target_lang="en"):
    try:
        # GPT-4 ëª¨ë¸ì„ ì‚¬ìš©í•´ ë²ˆì—­ ìˆ˜í–‰
        prompt = f"Translate the following text to {target_lang}: {text}"
        
        # GPT-4 API í˜¸ì¶œ
        response = openai.Completion.create(
            engine="gpt-4",  # ì‚¬ìš©í•  ëª¨ë¸ (gpt-3.5-turboë„ ì‚¬ìš© ê°€ëŠ¥)
            prompt=prompt,
            max_tokens=200,  # ë²ˆì—­ëœ í…ìŠ¤íŠ¸ì˜ ìµœëŒ€ ê¸¸ì´
            temperature=0.3  # ì‘ë‹µì˜ ì¼ê´€ì„±ì„ ìœ„í•œ ë‚®ì€ ì˜¨ë„ ì„¤ì •
        )
        
        # GPT-4 ì‘ë‹µì—ì„œ ë²ˆì—­ëœ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        translation = response.choices[0].text.strip()
        return translation
    
    except Exception as e:
        print(f"Error during translation: {e}")
        return text  # ë²ˆì—­ì— ì‹¤íŒ¨í•œ ê²½ìš° ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜
    
    
# í…ìŠ¤íŠ¸ ìž„ë² ë”© í›„ ì •ê·œí™”
def embed_text(text, model):
    #ë²ˆì—­ fn ë¨¼ì € ì‹¤í–‰ë˜ê²Œ ì¶”ê°€
    translated_text = translate_text(text, target_lang="en")

    text_embedding = model.encode_text([translated_text], batch_size=32)
    text_embedding = text_embedding / np.linalg.norm(text_embedding, ord=2, axis=-1, keepdims=True)
    return text_embedding

# ì´ë¯¸ì§€ ìž„ë² ë”© í•¨ìˆ˜ í›„ ì •ê·œí™”
def embed_image(image, model):
    image_embedding = model.encode_images([image], batch_size=32)
    image_embedding = image_embedding / np.linalg.norm(image_embedding, ord=2, axis=-1, keepdims=True)
    return image_embedding

# í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ ìž„ë² ë”© í›„ ì •ê·œí™”
def embed_text_and_image(user_text, user_image, fclip_model):
    text_embedding = embed_text(user_text, fclip_model)
    image_embedding = embed_image(user_image, fclip_model)
    return text_embedding, image_embedding
 
# ********************************
# ì‚¬ìš©ìž ì¸í’‹ íƒ€ìž…ì— ë”°ë¥¸ í˜¸ì¶œ
# ********************************

#pip install -U fashion_clip 
from fashion_clip.fashion_clip import FashionCLIP

fclip_model = FashionCLIP('fashion-clip')
if user_input or uploaded_file:
    # ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ë‘˜ ë‹¤ ìž…ë ¥ëœ ê²½ìš°
    if user_input and uploaded_file[-1]:
        image_filepath = process_imagefile(uploaded_file[-1])
        
        # í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µ ìƒì„±
        response = embed_text_and_image(user_input, uploaded_file[-1], fclip_model)
        
        # ì‚¬ìš©ìžì˜ ìž…ë ¥ ì²˜ë¦¬
        st.chat_message("user").write(f"í…ìŠ¤íŠ¸: {user_input}, ì´ë¯¸ì§€ ì—…ë¡œë“œë¨")

        # AIì˜ ì‘ë‹µ ì²˜ë¦¬
        with st.chat_message("assistant"):
            container = st.empty()
            ai_answer = ""
            for token in response:
                ai_answer += token.content
                container.markdown(ai_answer)

        # ëŒ€í™”ê¸°ë¡ ì €ìž¥
        add_message("user", f"í…ìŠ¤íŠ¸: {user_input}, ì´ë¯¸ì§€ ì—…ë¡œë“œë¨")
        add_message("assistant", ai_answer)

    # [ì‚¬ìš©ìž ì¸í’‹ì´ ì´ë¯¸ì§€ì¼ ê²½ìš°]
    elif uploaded_file:
        image_filepath = process_imagefile(uploaded_file[-1])

        # ì´ë¯¸ì§€ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µ ìƒì„±
        response = embed_image(uploaded_file[-1], fclip_model)

        # ì‚¬ìš©ìžì˜ ìž…ë ¥ ì²˜ë¦¬
        st.chat_message("user").write("ì´ë¯¸ì§€ ì—…ë¡œë“œë¨")

        # AIì˜ ì‘ë‹µ ì²˜ë¦¬
        with st.chat_message("assistant"):
            container = st.empty()
            ai_answer = ""
            for token in response:
                ai_answer += token.content
                container.markdown(ai_answer)

        # ëŒ€í™”ê¸°ë¡ ì €ìž¥
        add_message("user", "ì´ë¯¸ì§€ ì—…ë¡œë“œë¨")
        add_message("assistant", ai_answer)

    # [ì‚¬ìš©ìž ì¸í’‹ì´ í…ìŠ¤íŠ¸ì¼ ê²½ìš°]
    elif user_input:
        # í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µ ìƒì„±
        response = embed_text(user_input, fclip_model)

        # ì‚¬ìš©ìžì˜ ìž…ë ¥ ì²˜ë¦¬
        st.chat_message("user").write(user_input)

        # AIì˜ ì‘ë‹µ ì²˜ë¦¬
        with st.chat_message("assistant"):
            container = st.empty()
            ai_answer = ""
            for token in response:
                ai_answer += token.content
                container.markdown(ai_answer)

        # ëŒ€í™”ê¸°ë¡ ì €ìž¥
        add_message("user", user_input)
        add_message("assistant", ai_answer)          
        
from fashion_clip.fashion_clip import FashionCLIP

fclip_model = FashionCLIP('fashion-clip')
if user_input or uploaded_file:
    # ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ë‘˜ ë‹¤ ìž…ë ¥ëœ ê²½ìš°
    if user_input and uploaded_file:
        image_filepath = process_imagefile(uploaded_file)
        
        # í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µ ìƒì„±
        response = embed_text_and_image(user_input, uploaded_file, fclip_model)
        
        # ì‚¬ìš©ìžì˜ ìž…ë ¥ ì²˜ë¦¬
        st.chat_message("user").write(f"í…ìŠ¤íŠ¸: {user_input}, ì´ë¯¸ì§€ ì—…ë¡œë“œë¨")

        # AIì˜ ì‘ë‹µ ì²˜ë¦¬
        with st.chat_message("assistant"):
            container = st.empty()
            ai_answer = ""
            for token in response:
                ai_answer += token.content
                container.markdown(ai_answer)

        # ëŒ€í™”ê¸°ë¡ ì €ìž¥
        add_message("user", f"í…ìŠ¤íŠ¸: {user_input}, ì´ë¯¸ì§€ ì—…ë¡œë“œë¨")
        add_message("assistant", ai_answer)

    # [ì‚¬ìš©ìž ì¸í’‹ì´ ì´ë¯¸ì§€ì¼ ê²½ìš°]
    elif uploaded_file:
        image_filepath = process_imagefile(uploaded_file[-1])

        # ì´ë¯¸ì§€ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µ ìƒì„±
        response = embed_image(uploaded_file[-1], fclip_model)

        # ì‚¬ìš©ìžì˜ ìž…ë ¥ ì²˜ë¦¬
        st.chat_message("user").write("ì´ë¯¸ì§€ ì—…ë¡œë“œë¨")

        # AIì˜ ì‘ë‹µ ì²˜ë¦¬
        with st.chat_message("assistant"):
            container = st.empty()
            ai_answer = ""
            for token in response:
                ai_answer += token.content
                container.markdown(ai_answer)

        # ëŒ€í™”ê¸°ë¡ ì €ìž¥
        add_message("user", "ì´ë¯¸ì§€ ì—…ë¡œë“œë¨")
        add_message("assistant", ai_answer)

    # [ì‚¬ìš©ìž ì¸í’‹ì´ í…ìŠ¤íŠ¸ì¼ ê²½ìš°]
    elif user_input:
        # í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì‘ë‹µ ìƒì„±
        response = embed_text(user_input, fclip_model)

        # ì‚¬ìš©ìžì˜ ìž…ë ¥ ì²˜ë¦¬
        st.chat_message("user").write(user_input)

        # AIì˜ ì‘ë‹µ ì²˜ë¦¬
        with st.chat_message("assistant"):
            container = st.empty()
            ai_answer = ""
            for token in response:
                ai_answer += token.content
                container.markdown(ai_answer)

        # ëŒ€í™”ê¸°ë¡ ì €ìž¥
        add_message("user", user_input)
        add_message("assistant", ai_answer)        

import chromadb
import os

local_path = '/Users/jei/Downloads/'  
chroma_db = 'chromadb_j_0816'

# Chroma í´ë¼ì´ì–¸íŠ¸ ìƒì„±
client = chromadb.PersistentClient(path=local_path+chroma_db)

# ëª¨ë“  ì»¬ë ‰ì…˜ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
collections = client.list_collections()

# ì»¬ë ‰ì…˜ ì •ë³´ ì¶œë ¥
for collection in collections:
    print(f"Collection name: {collection.name}")
    print("-" * 40)
    
# ì €ìž¥ëœ ChromaDB ì»¬ë ‰ì…˜ ë¡œë“œ
img_collection = client.get_collection("outfit_img_embeddings")
txt_collection = client.get_collection("outfit_txt_embeddings")
products_collection = client.get_collection("products_metadatas")

# ë°ì´í„° ìˆ˜ í™•ì¸í•´ë³´ê¸°
print(f"img_collection ë°ì´í„° ìˆ˜ >> : {img_collection.count()}")
print(f"txt_collection  ë°ì´í„° ìˆ˜ >>> : {txt_collection.count()}")
print(f"products_collection  ë°ì´í„° ìˆ˜ >>> : {products_collection.count()}")
print("-" * 50)

