import streamlit as st
from langchain_core.messages.chat import ChatMessage
from langchain_openai import ChatOpenAI
from langchain_teddynote.models import MultiModal

from dotenv import load_dotenv
import os
#
#ìƒíƒœ ìš”ì•½: 
#
# API KEY ì •ë³´ë¡œë“œ
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")
if not openai_api_key:
    raise ValueError("[Error] OpenAI API Keyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤..")
        
# ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
if not os.path.exists(".cache"):
    os.mkdir(".cache")

# íŒŒì¼ ì—…ë¡œë“œ ì „ìš© í´ë”
if not os.path.exists(".cache/files"):
    os.mkdir(".cache/files")

if not os.path.exists(".cache/embeddings"):
    os.mkdir(".cache/embeddings")

st.set_page_config(page_title="AI Fashion Chatbot", page_icon="ğŸ‘š")
st.title(":gray[_AI FashionBot_]_Set the Looks ğŸ‘šğŸ”")

# í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ íŒŒì¼ëª…ì„ Streamlitì— í‘œì‹œ(ì–˜ ë„ˆë¬´ py ëŒì•„ê°€ë©´ì„œ ì‹¤í–‰í•´ì„œ í—·ê°ˆë ¤ì„œ ì¨ë†“ê¸°)
current_file_name = os.path.basename(__file__)
st.sidebar.write(f"py íŒŒì¼ëª…: `{current_file_name}`")

# ì²˜ìŒ 1ë²ˆë§Œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì½”ë“œ
if "messages" not in st.session_state:
    # ëŒ€í™”ê¸°ë¡ì„ ì €ì¥í•˜ê¸° ìœ„í•œ ìš©ë„ë¡œ ìƒì„±í•œë‹¤.
    st.session_state["messages"] = []

# ì‚¬ì´ë“œë°” ìƒì„±
with st.sidebar:
    # ì´ˆê¸°í™” ë²„íŠ¼ ìƒì„±
    clear_btn = st.button("ëŒ€í™” ì´ˆê¸°í™”")

    # ì´ë¯¸ì§€ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader("ì´ë¯¸ì§€ ì—…ë¡œë“œ", type=["jpg", "jpeg", "png"], accept_multiple_files=True)
    
    # Process ë²„íŠ¼ ëˆŒë €ì„ ë•Œ ì´ë²¤íŠ¸ ì •ì˜
    #process = st.button("Process")
    
    system_prompt = st.text_area(
    "system", 
        """
        Your task is to classify the user's intent into one of the following categories: ["Fashion Recommendation", "Fashion Feedback", "General Conversation"].
        Based on the user's intent, generate a natural, friendly, and conversational response in Korean. Use emojis when appropriate, and do not show the classification process to the user. The user should only see the final response.

        - **Fashion Recommendation**: The user is asking for fashion advice, outfit suggestions, or styling recommendations. Examples include phrases like "ë¬´ìŠ¨ ì˜·ì„ ì…ì–´ì•¼ í• ê¹Œìš”?", "ì´ ë“œë ˆìŠ¤ì— ë§ëŠ” ì‹ ë°œì„ ì¶”ì²œí•´ì¤˜.", "ìš”ì¦˜ ìœ í–‰ì´ ë­ëƒ", or "ì—¬ë¦„ì— ì–´ìš¸ë¦¬ëŠ” ìŠ¤íƒ€ì¼ì´ ë­ê°€ ìˆì„ê¹Œ?".
        - **Fashion Feedback**: The user is providing feedback on a fashion item, discussing personal preferences, or commenting on a suggested style. Examples include phrases like "ì´ ì˜· ì–´ë•Œ", "ì¹œêµ¬ë“¤ì´ë‘ ì—¬í–‰ê°€ëŠ”ë° ì´ëŸ° ë³µì¥ ì–´ë–¨ê¹Œ", or "ì¥ë¡€ì‹ì—ì„œ ì…ì–´ë„ ë¼?".
        - **General Conversation**: The user is engaging in casual conversation unrelated to fashion advice or feedback. This could be small talk, general questions, or any other non-fashion related inquiry. Examples include phrases like "ì˜¤ëŠ˜ ë‚ ì”¨ê°€ ì–´ë•Œìš”?", "ì–´ì œ ì˜í™” ë´¤ì–´?", "ì•„ ë°°ê³ í”„ë‹¤" or "ì§€ê¸ˆ ëª‡ ì‹œì˜ˆìš”?".

        Based on the classification, respond naturally without revealing the classification to the user.

        ====
        def classify(sentence: str) -> Literal["Fashion Recommendation", "Fashion Feedback", "General Conversation"]:
            Classify the user's sentence into one of the categories based on their intent.

            Args:
                sentence (str): The sentence that needs to be classified.

            Returns:
                Literal["Fashion Recommendation", "Fashion Feedback", "General Conversation"]: The classification of the sentence.
        ====
        # Generate a natural, friendly, conversational response in Korean based on the classification:
         if result == "Fashion Recommendation":
            return "ì´ ìŠ¤íƒ€ì¼ì€ ì •ë§ ì„¸ë ¨ë˜ë©´ì„œë„ ìœ ë‹ˆí¬í•œ ëŠë‚Œì„ ì¤„ ìˆ˜ ìˆì–´ìš”! âœ¨ \n\n\
                    ì œê°€ ì¶”ì²œë“œë¦¬ëŠ” ìœ ì‚¬í•œ íŒ¨ì…˜ì€ ì´ ìŠ¤íƒ€ì¼ê³¼ ì˜ ì–´ìš¸ë¦¬ëŠ” íŠ¸ë Œë””í•œ ì•„ì´í…œë“¤ì…ë‹ˆë‹¤. ğŸ‘—ğŸ‘  \n\
                    íŠ¹íˆ, ì´ ë“œë ˆìŠ¤ëŠ” ë‹¤ì–‘í•œ ì•¡ì„¸ì„œë¦¬ì™€ í•¨ê»˜ ë§¤ì¹˜í•˜ë©´ ë”ìš± ë‹ë³´ì¼ ê±°ì˜ˆìš”. ğŸ˜Š \n\n\
                    ì—¬ë¦„ì—ë„ ì…ê¸° ì¢‹ì€ ì‹œì›í•œ ì†Œì¬ë¡œ ì œì‘ë˜ì—ˆê³ , ë°ì¼ë¦¬ ë£©ìœ¼ë¡œë„ ì™„ë²½í•˜ê²Œ ì–´ìš¸ë¦´ ê±°ì˜ˆìš”. \n\
                    ì´ ìŠ¤íƒ€ì¼ë¡œ ì‹œë„í•´ë³´ì‹œë©´ ë§ì€ ì‚¬ëŒë“¤ì´ ëˆˆì—¬ê²¨ë³´ê²Œ ë  ê±°ì˜ˆìš”! ğŸ‘"
        elif result == "Fashion Feedback":
            return "ì´ ì´ë¯¸ì§€ì— ìˆëŠ” ì•„ì´í…œì€ ì •ë§ ë©‹ì§€ë„¤ìš”! ğŸ‰ \n\n\
                    ì´ ìŠ¤íƒ€ì¼ì€ ë‹¤ì–‘í•œ ì½”ë””ì— ì˜ ì–´ìš¸ë¦´ ê²ƒ ê°™ì•„ìš”. ğŸ˜Š \n\
                    íŠ¹íˆ ì´ ì•„ì´í…œì€ ì–´ë–¤ ë£©ì—ë„ í¬ì¸íŠ¸ë¥¼ ì¤„ ìˆ˜ ìˆì–´ì„œ í™œìš©ë„ê°€ ë†’ì„ ê²ƒ ê°™ì•„ìš”!"
        elif result == "General Conversation":
            return "ê·¸ë ‡êµ°ìš”! ğŸ˜„ ì˜¤ëŠ˜ í•˜ë£¨ë„ ë©‹ì§„ í•˜ë£¨ ë³´ë‚´ì„¸ìš”! â˜€ï¸"
        
        Do not reveal the classification to the user. Only show the final response based on the classification.
        ("human", "{human}")
            """,
        height=100,
    )
    
    
# ì´ì „ ëŒ€í™”ë¥¼ ì¶œë ¥
def print_messages():
    for chat_message in st.session_state["messages"]:
        st.chat_message(chat_message.role).write(chat_message.content)


# ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ì¶”ê°€
def add_message(role, message):
    st.session_state["messages"].append(ChatMessage(role=role, content=message))


# ì´ë¯¸ì§€ì„ ìºì‹œ ì €ì¥(ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ëŠ” ì‘ì—…ì„ ì²˜ë¦¬í•  ì˜ˆì •)
@st.cache_resource(show_spinner="ğŸ‘— ì—…ë¡œë“œí•œ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤...")
def process_imagefile(file):
    # ì—…ë¡œë“œí•œ íŒŒì¼ì„ ìºì‹œ ë””ë ‰í† ë¦¬ì— ì €ì¥í•©ë‹ˆë‹¤.
    file_content = file.read()
    file_path = f"./.cache/files/{file.name}"

    with open(file_path, "wb") as f:
        f.write(file_content)

    return file_path


# í…ìŠ¤íŠ¸ ê¸°ë°˜ ë‹µë³€ ìƒì„±
def generate_text_answer(system_prompt, user_prompt, model_name):
    # ê°ì²´ ìƒì„±
    llm = ChatOpenAI(
        temperature=0,
        model_name=model_name,  # ëª¨ë¸ëª…
    )

    # GPT-4 ëª¨ë¸ì„ ì‚¬ìš©í•´ í…ìŠ¤íŠ¸ ê¸°ë°˜ì˜ ì‘ë‹µ ìƒì„±
    messages = [
        ChatMessage(role="system", content=system_prompt),
        ChatMessage(role="user", content=user_prompt)
    ]
    response = llm(messages)
    
    return response.content  # AIMessage ê°ì²´ì˜ content ì†ì„±ì„ ë°˜í™˜


# ì²´ì¸ ìƒì„± (ì´ë¯¸ì§€ ê¸°ë°˜ ë©€í‹°ëª¨ë‹¬ ì‘ë‹µ ìƒì„±)
def generate_multimodal_answer(image_filepath, system_prompt, user_prompt, model_name):
    # ê°ì²´ ìƒì„±
    llm = ChatOpenAI(
        temperature=0,
        model_name=model_name,  # ëª¨ë¸ëª…
    )

    # ë©€í‹°ëª¨ë‹¬ ê°ì²´ ìƒì„± (ì˜ˆì‹œë¡œ MultiModal ì‚¬ìš©)
    multimodal = MultiModal(llm, system_prompt=system_prompt, user_prompt=user_prompt)

    # ì´ë¯¸ì§€ íŒŒì¼ë¡œë¶€í„° ì§ˆì˜(ìŠ¤íŠ¸ë¦¼ ë°©ì‹)
    answer = multimodal.stream(image_filepath)
    return answer


# ì´ˆê¸°í™” ë²„íŠ¼ì´ ëˆŒë¦¬ë©´...
if clear_btn:
    st.session_state["messages"] = []

# ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶œë ¥
print_messages()

# ì‚¬ìš©ìì˜ ì…ë ¥
user_input = st.chat_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”!")

# ê²½ê³  ë©”ì‹œì§€ë¥¼ ë„ìš°ê¸° ìœ„í•œ ë¹ˆ ì˜ì—­
warning_msg = st.empty()

# ë§Œì•½ì— ì‚¬ìš©ì ì…ë ¥ì´ ë“¤ì–´ì˜¤ë©´...
if user_input:
    # ì‚¬ìš©ìì˜ ì…ë ¥ì„ ì¶”ê°€
    st.chat_message("user").write(user_input)

    if uploaded_file:
        # ë¦¬ìŠ¤íŠ¸ì˜ ë§ˆì§€ë§‰ ì´ë¯¸ì§€ë¡œ ê³„ì† ëŒ€í™”í•˜ê²Œ ì¶”ê°€
        new_uploaded_file = uploaded_file[-1]  
        # ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ì´ë¯¸ì§€ì™€ í•¨ê»˜ ì²˜ë¦¬
        image_filepath = process_imagefile(new_uploaded_file)
        
        # ì´ë¯¸ì§€ ì‹œê°í™” ì¶”ê°€
        with st.chat_message("user"):
            #st.image(image_filepath, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€")
            st.image(image_filepath, caption=f"ì—…ë¡œë“œëœ ì´ë¯¸ì§€: {new_uploaded_file.name}")  # íŒŒì¼ëª… ì¶”ê°€

        response = generate_multimodal_answer(image_filepath, system_prompt, user_input, "gpt-4o")

        with st.chat_message("assistant"):
            # ë¹ˆ ê³µê°„(ì»¨í…Œì´ë„ˆ)ì„ ë§Œë“¤ì–´ì„œ, ì—¬ê¸°ì— í† í°ì„ ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥í•œë‹¤.
            container = st.empty()

            ai_answer = ""
            for token in response:
                ai_answer += token.content
                container.markdown(ai_answer)

        # ëŒ€í™”ê¸°ë¡ì„ ì €ì¥í•œë‹¤.
        add_message("user", user_input)
        add_message("assistant", ai_answer)

    else:
        # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ì²˜ë¦¬
        text_answer = generate_text_answer(system_prompt, user_input, "gpt-4")

        with st.chat_message("assistant"):
            st.write(text_answer)

        # ëŒ€í™”ê¸°ë¡ì„ ì €ì¥í•œë‹¤.
        add_message("user", user_input)
        add_message("assistant", text_answer)